{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Derivatives I\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: false\n",
    "    page-layout: full\n",
    "    fig-cap-location: bottom\n",
    "    number-sections: true\n",
    "    number-depth: 2\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "## Example from Physics\n",
    "We use derivatives everywhere in physics, for example:\n",
    "\n",
    "- In classical mechanics, the _velocity_ of a single particle is:\n",
    "$$\n",
    "\\boldsymbol{v} = \\frac{d\\boldsymbol{r}}{dt}\n",
    "$$\n",
    "where $\\boldsymbol{r}$ is the position of the particle in a given reference frame. \n",
    "\n",
    "- In classical electromagnetism, the equation connecting the electric field $\\boldsymbol{E}$ with the vector potential $\\boldsymbol{A}$ and scalar potential $\\phi$ is:\n",
    "$$\n",
    "\\boldsymbol{E} = -\\nabla \\phi  - \\frac{\\partial A}{\\partial t}.\n",
    "$$\n",
    "\n",
    "- The Lagrangian density for the vibrations of a continuous rod can be expressed as \n",
    "$$\n",
    "\\mathcal{L}  = \\frac{1}{2}\\left[\\frac{1}{c^2}\n",
    "\\left(\\frac{\\partial \\varphi}{\\partial t}\\right)^2 \n",
    "-\\left(\\frac{\\partial \\varphi}{\\partial x}\\right)^2\\right].\n",
    "$$\n",
    "Here $c$ is the velocity of longitudinal elastic waves. The dynamical variable is $\\varphi(x,t)$.\n",
    "As you can see, the spatial and temporal derivatives of this quantity together make up the Lagrangian density. \n",
    "\n",
    "## The Problem to be Solved\n",
    "- Generally, our task is to evaluate the derivative of $f(x)$ at a specific point, $f'(x)$. \n",
    "- If $f'(x)$ can be evaluated analytically, then this problem is trivial.\n",
    "- However, in lots of cases, either $f(x)$ has a very complicated expression, or we only know the numerical values of $f(x)$ at a few points, namely, we have a table of the form\n",
    "$(x_i, f(x_i))$ for $i = 0, 1, \\dots, n-1$.\n",
    "\n",
    "We could approach this problem in a number of ways: \n",
    "\n",
    "- We can use interpolation or data fitting to produce a new function that approximates the data reasonably well, and then apply _analytical differentiation_ to that function. This is helpful for noisy data. On the other hand, the approxixmation may not be able to capture the derivatives.\n",
    "- The second approach is the _finite-difference_ approach, also known as _numerical dfferentiation_. This makes use of the Taylor series expansion.\n",
    "- The third approach is the _automatic differentiation_: this is as accurate as analytical differentiation, but it deals with numbers instead of mathematical expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Differentiation\n",
    "Derivatives are defined as\n",
    "$$\n",
    "\\frac{d f(x)}{dx} = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "You can calculate the analytical expressions by hand, based on the chain rulles etc. Alternatively, you can also use a _computer algebra system (CAS)_. There are commercial softwares: `Mathematica` and `Maple`. There are also free options. One such example is `Sage`, which is a mathematical software system with a \"Python-like\" syntax. \n",
    "In one of the problems, we focus on a much more lightweight solution, namely `SymPy` (actually included as part of `Sage`): this is a Python module (that can be used like any other Python module) to carry out symbolic manipulations using Python idioms whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Finite Differences\n",
    "Let us rewrite the definition of the derivative\n",
    "$$\n",
    "\\left.\\frac{d f(x)}{dx}\\right|_{x=\\tilde{x}} = \\lim_{h \\to 0} \\frac{f(\\tilde{x} + h) - f(\\tilde{x})}{h}\n",
    "$$\n",
    "where we are slightly changing our notation to show that this definition allows us to evaluate the derivative of $f(x)$ at point $\\tilde{x}$.\n",
    "\n",
    "Numerically, one can apply this formula without taking the limit, but take $h$ to be \"small\". But there are many questions that emerge with this approach.\n",
    "\n",
    "1. do we have any understanding of the errors ?\n",
    "   \n",
    "2. do we know what \"small\" means ?\n",
    "   \n",
    "3. do we realize that the smaller $h$ becomes, the smaller the numerator becomes? Namely, as $h$ becomes smaller and smaller, both numerator and denominator become smaller.\n",
    "Any errors appearing in the calculation of the numerator will then be magnified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noncentral-Difference Approximations\n",
    "### Forward Difference\n",
    "Recall the Taylor expansion of $f(x+h)$ around $x$:\n",
    "$$\n",
    "f(x+h) = f(x) + h f'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{3!}f'''(x) + \\cdots,\n",
    "$$\n",
    "which can be re-arranged into\n",
    "$$\n",
    "f'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{h}{2}f''(x) + \\cdots.\n",
    "$$\n",
    "This leads to \n",
    "$$\n",
    "f'(x) =\\frac{f(x+h) - f(x)}{h} + O(h),\n",
    "$$\n",
    "known as the _(first) forward-difference approximation_, which has an error $O(h)$. \n",
    "Graphically, this is just the slope of the line segment connecting $f(x)$ and $f(x+h)$, see left of @fig-finite_difference.\n",
    "\n",
    "![First approximation of a first derivative: forward (left), central (right)](finite_difference.png){#fig-finite_difference}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Difference\n",
    "We can also perform a Taylor expansion of $f(x-h)$ near $f(x)$. This will lead to\n",
    "$$\n",
    "f'(x) =\\frac{f(x) - f(x-h)}{h} + O(h),\n",
    "$$\n",
    "known as the _(first) backward-difference approximation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis for the Forward Difference\n",
    "There are two errors involved in this problem (we use $\\mathcal{E}$ to denote the magnitude of the absolute error):\n",
    "\n",
    "1. the approximation error $\\mathcal{E}_{app}$, coming from the truncation of the Taylor series.\n",
    "\n",
    "2. the roundoff error $\\mathcal{E}_{ro}$, coming from the subtraction and division involved in the definition of the forward difference.\n",
    "\n",
    "Here, the approximation error is $\\mathcal{E}_{app} = \\frac{h}{2} |f''(x)|$.\n",
    "\n",
    "Turning to $\\mathcal{E}_{ro}$, where we are interested in computing\n",
    "$[f(x+h)-f(x)]/h$. We focus on the numerator: we are subtracting two numbers that are very close to each other. The absolute error for the numerator is $f(x)2\\epsilon_m$, where we approximate $f(x+h)\\simeq f(x)$ and we assume the relative error for each function is the machine error $\\epsilon_m = 2.2 \\times 10^{-16}$. If we now ignore the error in the denominator, we can write \n",
    "$$\n",
    "\\mathcal{E}_{ro} = \\frac{2|f(x)|\\epsilon_m}{h}.\n",
    "$$\n",
    "\n",
    "We can write the total absolute error \n",
    "$$\n",
    "\\mathcal{E} = \\mathcal{E}_{app} + \\mathcal{E}_{ro}\n",
    " = \\frac{h}{2}|f''(x)| + \\frac{2|f(x)|\\epsilon_m}{h}.\n",
    "$${#eq-total-error}\n",
    "\n",
    "We see that $\\mathcal{E}_{app}$ decreases as $h$ is decreased. On the other hand, $\\mathcal{E}_{ro}$ increases as $h$ is decreased.\n",
    "\n",
    "To minimize the total error, take the derivative with respect to $h$ and then set it to zero, we find\n",
    "$$\n",
    "\\frac{1}{2}|f''(x)| - \\frac{2|f(x)|\\epsilon_m}{h_{opt}^2} = 0.\n",
    "$$\n",
    "This gives the optimal $h = h_{opt}$, with\n",
    "$$\n",
    "h_{opt} = \\sqrt{ 4\\epsilon_m \\left|\\frac{f(x)}{f''(x)} \\right| }.\n",
    "$${#eq-opt-cond}\n",
    "\n",
    "By @eq-total-error, we have that the optimal (minimum) error is\n",
    "$$\n",
    "\\mathcal{E}_{opt} = \\frac{h_{opt}}{2}|f''(x)| + \\frac{2|f(x)|\\epsilon_m}{h_opt} = \n",
    "h_{opt}|f''(x)|,\n",
    "$$\n",
    "where in the second equality we have used @eq-opt-cond. This finally gives\n",
    "$$\n",
    "\\mathcal{E}_{opt} = \\sqrt{4\\epsilon_m|f(x) f''(x)|}.\n",
    "$$\n",
    "\n",
    "For concreteness, assuming that $f(x)$ and $f''(x)$ are of order 1, we can obtain\n",
    "that $h_{opt} = \\sqrt{4\\epsilon_m} \\simeq 3 \\times 10^{-8}$, and $\\mathcal{E}_{opt} \\simeq 3\\times 10^{-8}$.\n",
    "\n",
    "Note that $10^{-8}$ error is not impressive. In analytical differentiation, the only error comes from function evaluation, which is a less important problem. \n",
    "\n",
    "Another remark here is that the error analysis is on well behaved functions. The point of function evaluations should be away from singularties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central-Difference Approximation\n",
    "Consider Taylor expansion of $f(x\\pm\\frac{h}{2})$:\n",
    "$$\n",
    "f(x \\pm \\frac{h}{2}) = f(x) \\pm \\frac{h}{2}f'(x) + \\frac{h^2}{8}f''(x) \\pm \n",
    "\\frac{h^3}{48} f'''(x) + \\cdots.\n",
    "$$\n",
    "If we evaluate $f(x+\\frac{h}{2}) - f(x - \\frac{h}{2})$, we see that the $f''(x)$ term get cancelled out. In fact, all even order of derivatives cancel out. Thus, we have\n",
    "$$\n",
    "f'(x) = \\frac{f(x + \\frac{h}{2}) - f(x - \\frac{h}{2})}{h} - \\frac{h^2}{24}f'''(x)+ \\cdots,\n",
    "$$\n",
    "this leads to \n",
    "$$\n",
    "f'(x) = \\frac{f(x + \\frac{h}{2}) - f(x - \\frac{h}{2})}{h}  + O(h^2),\n",
    "$$\n",
    "known as the _(first) central difference approximation_. Note that the error is of second order of the small number $h$. This is graphically illustrated in @fig-finite_difference.\n",
    "\n",
    "There exists one (very common in practice) situation where a central-difference approximation is simply not usable: : if we have a set of $n$ discrete data points of the form $(x_i, f(x_i))$ for $i = 0,1,\\dots,n-1$, we will not be able to use a central difference to approximate the derivative at $x_0$ or at $x_{n-1}$. So at the boundary points we have to use forward/backward difference method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis for the Central Difference\n",
    "Similar to the error analysis in the forward case, the total error (see homework problem) here is\n",
    "$$\n",
    "\\mathcal{E} = \\mathcal{E}_{app} + \\mathcal{E}_{ro} \n",
    "= \\frac{h^2}{24}|f'''(x)| + \\frac{2|f(x)|\\epsilon_m}{h}.\n",
    "$$\n",
    "\n",
    "You will also show that\n",
    "$$\n",
    "h_{opt} = \\left(24 \\epsilon_m \\left|\\frac{f(x)}{f'''(x)}\\right|\\right)^{1/3},\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\mathcal{E}_{opt} = \\left(\\frac{9}{8}\\epsilon_m^2[f(x)]^2\\left|f'''(x)\\right|\\right)^{1/3}.\n",
    "$$\n",
    "Taking $f(x)$ and $f'''(x)$ of order 1, we can estimate $h_{opt} \\simeq 2 \\times 10^{-5}$ and $\\mathcal{E}_{opt}\\simeq 4 \\times 10^{-11}$. We see the improvements compared with the errors in forward difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Let us work on a concrete function $f(x) = e^{\\sin(2x)}$. We can analytically compute its derivative\n",
    "$$\n",
    "f'(x) = 2\\cos(2x)e^{\\sin(2x)}.\n",
    "$$\n",
    "The following program will compute the derivate of $f(x)$ at $x = 0.5$, using finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h     abs. error in fd   abs. error in cd\n",
      "1e-01 0.3077044583376249 0.0134656094697734\n",
      "1e-02 0.0260359156900742 0.0001350472493096\n",
      "1e-03 0.0025550421497806 0.0000013505120728\n",
      "1e-04 0.0002550180941236 0.0000000135077878\n",
      "1e-05 0.0000254969542519 0.0000000001495843\n",
      "1e-06 0.0000025492660578 0.0000000002500959\n",
      "1e-07 0.0000002564334673 0.0000000011382744\n",
      "1e-08 0.0000000189018428 0.0000000189018428\n",
      "1e-09 0.0000003741732106 0.0000000699159992\n",
      "1e-10 0.0000021505300500 0.0000021505300500\n",
      "1e-11 0.0000332367747395 0.0000111721462455\n"
     ]
    }
   ],
   "source": [
    "from math import exp, sin, cos, log10\n",
    "\n",
    "def f(x):\n",
    "    return exp(sin(2*x))\n",
    "\n",
    "def fprime(x):\n",
    "    return 2*exp(sin(2*x))*cos(2*x)\n",
    "\n",
    "def calc_fd(f,x,h):\n",
    "    fd = (f(x+h) - f(x))/h\n",
    "    return fd\n",
    "\n",
    "def calc_cd(f,x,h):\n",
    "    cd = (f(x+h/2) - f(x-h/2))/h\n",
    "    return cd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = 0.5\n",
    "    an = fprime(x)\n",
    "\n",
    "    hs = [10**(-i) for i in range(1,12)]\n",
    "    fds = [abs(calc_fd(f,x,h) - an) for h in hs]\n",
    "    cds = [abs(calc_cd(f,x,h) - an) for h in hs]\n",
    "\n",
    "    rowf = \"{0:1.0e} {1:1.16f} {2:1.16f}\"\n",
    "    print(\"h     abs. error in fd   abs. error in cd\")\n",
    "    for h,fd,cd in zip(hs,fds,cds):\n",
    "        print(rowf.format(h,fd,cd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the error as a function of $h$, using `matplotlib`, with `plt.loglog(x,y)`, which plots the data in the log-log scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(hs,fds,'o-',label='forward diff.')\n",
    "plt.loglog(hs,cds,'s--',label='central diff.')\n",
    "plt.xlabel('h')\n",
    "plt.ylabel('|abs. error|')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Accurate Finite Differences\n",
    "In the previous section, we have derived the forward and central finite difference approximations, which require two function evaluations.\n",
    "\n",
    "As you will show in your homework, one can produce the following approximation for the value of the derivative of $f(x)$ at x:\n",
    "$$\n",
    "f'(x) = \\frac{4f(x+\\frac{h}{2}) - f(x+h) - 3f(x)}{h} + \\frac{h^2}{12}f'''(x) + \\cdots \n",
    "$$\n",
    "known as the _second forward-difference approximation_.\n",
    "This gives an error $O(h^2)$, at the cost of requiring three function evaluations:\n",
    "$f(x)$, $f(x+h/2)$, and $f(x+h)$.\n",
    "\n",
    "You can also show that\n",
    "$$\n",
    "f'(x) = \\frac{27f(x+\\frac{h}{2}) + f(x - \\frac{3}{2}h) - 27 f(x-\\frac{h}{2}) - f(x+\\frac{3}{2}h)}{24h} + \\frac{3}{640}h^4f^{(5)}(x) + \\cdots,\n",
    "$$ \n",
    "known as the _second central-difference approximation_. This has an error of $O(h^4)$, at the cost of requiring four function evaluations: $f(x+3h/2)$, $f(x+h/2)$, $f(x-h/2)$ and $f(x - 3h/2)$. \n",
    "\n",
    "One observation is that the sum of coefficients in the finite-difference formula is zero: $27 + 1 - 27 -1 = 0$ in the above case. \n",
    "\n",
    "This can be generalized by incorporating more points in order to obtain a better approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second order derivatives are also very important in physics. We can compute it numerically once we have first derivatives, via, for example\n",
    "$$\n",
    "f''(x)  = \\frac{f'(x+\\frac{h}{2}) - f'(x - \\frac{h}{2})}{h} + O(h^2).\n",
    "$$\n",
    "\n",
    "This can also be derived by adding $f(x+h/2)$ and $f(x - h/2)$,\n",
    "$$\n",
    "f(x+h/2) + f(x - h/2) = 2f(x) + \\frac{h^2}{4}f''(x) + \\frac{h^4}{192}f^{(4)}(x)\n",
    "+ \\cdots .\n",
    "$$\n",
    "This can be re-arranged into te form\n",
    "$$\n",
    "\\begin{align*}\n",
    "f''(x) &= 4\\frac{f(x + h/2) +f(x-h/2) - 2f(x)}{h^2} - \\frac{h^2}{48}f^{(4)}(x) + \\cdots \\\\\n",
    "&=4\\frac{f(x + h/2) +f(x-h/2) - 2f(x)}{h^2} + O(h^2),\n",
    "\\end{align*}\n",
    "$$\n",
    "which is known as the _(first) central-difference approximation_ to the second derivative. \n",
    "\n",
    "Higher order of derivatives can also be derived in a similar fashion based on Taylor expansion, although this is not too common in physics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points on a Grid\n",
    "So far, we have assume that we can evaluate the function at any points of $x$, in order to compute the derivatives. This does not happen sometimes in practice. Instead, in those cases we have access only to a set of $n$ discrete data points, $(x_i, f(x_i))$ for $i = 0,1,\\dots, n-1$.\n",
    "\n",
    "### Avoiding Error Creep\n",
    "A very common use case is when the points $x_i$ are on an equally spaced grid (also known as a mesh), from $a$ to $b$. The $n$ points are then given by the following relation:\n",
    "$$\n",
    "x_i = a + ih,\n",
    "$$\n",
    "where $i = 0,\\dots,n-1$ and \n",
    "$$\n",
    "h = \\frac{b - a}{n-1}.\n",
    "$$\n",
    "\n",
    "In python, you can store $x_i$ into a list `xs = [a + i*h for i in range(n)]`. Note that `range(n)` automatically ensures that $i$ goes from $0$ to $n-1$.\n",
    "\n",
    "Someone may think to take an alternative approach by considering a running `x`, and update `x` via `x += h` every time. This has a drawback because when every time you update $x$, you introduce an error in $h$ and the error will accumulate, which can be a problem when you have thousands of points. This issue is known as \"_systematic creep_\". Instead, if you update the `x` via `x = a + i*h`, you can avoid systematic creep because every time `x` is obtained by two operations: multiplication and addition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite-Difference Formulas\n",
    "Now let us calculate the first derivative of $f(x)$ at the points $x_i$. To be concrete, we have 101 points from 0 to 5. This leads to a step size of $h = 0.05$: $0, 0.05, 0.1, 0.15, \\dots, 5.0$. For example, we are interested in $f'(3.7)$\n",
    "but the neighboring values at our disposal are only $f(3.65)$, $f(3.7)$, and $f(3.75)$.\n",
    "\n",
    "We can use the forward difference formula\n",
    "$$\n",
    "f'(3.7) = \\frac{f(3.75) - f(3.7)}{h} + O(h).\n",
    "$$\n",
    "\n",
    "However, things are not so simple for the case of of central-difference formula, which requires $f(3.675)$ and $f(3.725)$. \n",
    "\n",
    "What we can do instead, is to double $h$, by choosing $h = 0.1$, then we only need $f(3.65)$, and $f(3.75)$, with the modified formula\n",
    "$$\n",
    "f'(x) = \\frac{f(x+h) - f(x-h)}{2h} + O(h^2).\n",
    "$$\n",
    "With this \"doubling\" trick, one can also compute the second order derivative via\n",
    "$$\n",
    "f''(x) = \\frac{f(x+h) + f(x - h) - 2f(x)}{h^2} + O(h^2).\n",
    "$$\n",
    "\n",
    "The error for the first central-difference first derivative with $h\\to 2h$ is then\n",
    "$$\n",
    "\\mathcal{E} = \\mathcal{E}_{app} + \\mathcal{E}_{ro} = \\frac{h^2}{6}|f'''(x)| + \n",
    "\\frac{|f(x)|\\epsilon_m}{h}.\n",
    "$$\n",
    "You can see that it still has an error $O(h^2)$. It is safe to say central-difference is better than the forward-difference in most cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "1. Show that total error of the central-difference for the first derivative is\n",
    "$$\n",
    "\\mathcal{E} = \\mathcal{E}_{app} + \\mathcal{E}_{ro} \n",
    "= \\frac{h^2}{24}|f'''(x)| + \\frac{2|f(x)|\\epsilon_m}{h}.\n",
    "$$\n",
    "Please use the above results to show the optimal parameter is\n",
    "$$\n",
    "h_{opt} = \\left(24 \\epsilon_m \\left|\\frac{f(x)}{f'''(x)}\\right|\\right)^{1/3},\n",
    "$$\n",
    "which gives rise to the minimal error\n",
    "$$\n",
    "\\mathcal{E}_{opt} = \\left(\\frac{9}{8}\\epsilon_m^2[f(x)]^2\\left|f'''(x)\\right|\\right)^{1/3}.\n",
    "$$\n",
    "2. Please derive the _second forward-difference approximation_\n",
    "$$\n",
    "f'(x) = \\frac{4f(x+\\frac{h}{2}) - f(x+h) - 3f(x)}{h} + \\frac{h^2}{12}f'''(x) + \\cdots .\n",
    "$$\n",
    "3. Please derive the _second central-difference approximation_\n",
    "$$\n",
    "f'(x) = \\frac{27f(x+\\frac{h}{2}) + f(x - \\frac{3}{2}h) - 27 f(x-\\frac{h}{2}) - f(x+\\frac{3}{2}h)}{24h} + \\frac{3}{640}h^4f^{(5)}(x) + \\cdots.\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df1fa0d82bdabb5288f7efc0788d29c4d5bb5f690328690a3d32d2cd65de760c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
